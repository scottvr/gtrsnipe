## Pipeline:

`Audio File → [1. Demucs] → Guitar Stem → [2. (Optional) NoiseReduce] → Clean Stem → [3. Basic-Pitch] → MIDI Data → [4. GtrSnipe Core] → ASCII Tab`

## Components
- source separation: demucs
- pitch detection: basic-pitch
- audio cleanup: noise-reduce
- libroso

## CLI changes
Remove positional arguments for filenames:
```
Flag	Argument	Description
-i, --input	FILE_PATH	Required. Path to the input file (.mid, .mp3, .wav, etc.).
-o, --output	FILE_PATH	Required. Path to the output file (.tab, .mid, etc.).
```

New feature options:
```
--stem	Flag	Step 1: Enables source separation (Demucs) to isolate a guitar stem.
--nr	Flag	Step 2: Enables noise/reverb reduction on the audio stem.
--p2m	Flag	Step 3: Enables pitch-to-MIDI conversion on the audio stem.
```

# Tasks
### Task 1: CLI Refactoring (High Priority)
Modify converter.py to adopt the new argument structure.

Change input_file and output_file from positional arguments to required optional flags: -i, --input and -o, --output.

Add the new boolean flags: --stem, --nr, and --p2m.

### Task 2: Smart Input/Output Handling
The main function will become a pipeline orchestrator.

Input Detection: After parsing arguments, check the file extension of args.input. If it's not a known MIDI/text format, assume it's audio and set an internal flag, e.g., is_audio_input = True.

Pipeline Logic: The workflow will be a chain of steps. The output of one step becomes the input to the next.

```
current_file = args.input

if is_audio_input and args.stem: → current_file = separate_instrument(current_file)

if is_audio_input and args.nr: → current_file = cleanup_audio(current_file)

if is_audio_input and args.p2m: → current_file = transcribe_to_midi(current_file)
```

**Flexible Output:** After the pipeline runs, check the extension of args.output. If current_file is a MIDI path and args.output ends in .mid, simply copy the final generated MIDI to the output path and exit.

**Final Conversion:** If the final output is .tab (or another text format), load current_file (which should now be a MIDI file) into a Song object and pass it to the existing MusicConverter for the "last mile" of transcription.

### Task 3: Component Implementation
The component modules (audio_separator.py, pitch_detector.py) remain the same as in the previous plan. Their functions will now be called conditionally based on the new flags.

Proposed CLI Usage
This new design allows for incredible flexibility.

Full Audio-to-Tab:
Run the complete pipeline from a mixed audio file to a tab in Drop D tuning.

```bash
gtrsnipe -i "song.mp3" -o "song.tab" --stem --nr --p2m --tuning DROP_D
```

Audio-to-MIDI Only:
Extract the guitar part from a song and save it as a MIDI file, stopping there.

```
gtrsnipe -i "song.wav" -o "song.mid" --stem --p2m
```

Partial Pipeline:
Transcribe an audio file that is already a clean guitar stem (no stemming or NR needed).

```
gtrsnipe -i "my_clean_riff.wav" -o "riff.mid" --p2m
```

Existing MIDI-to-Text Functionality (Unchanged):
The original functionality remains simple and direct.

```
gtrsnipe -i "track.mid" -o "track.tab" --prefer-open
```
